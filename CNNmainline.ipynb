{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df09a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\programdata\\anaconda3\\lib\\site-packages (0.10.2)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: absl-py in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (4.8.0.74)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (1.20.3)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Collecting tensorflow-intel==2.13.0\n",
      "  Using cached tensorflow_intel-2.13.0-cp39-cp39-win_amd64.whl (276.5 MB)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.12.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.56.0-cp39-cp39-win_amd64.whl (4.2 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.2.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.10.0.2)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (58.0.4)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (21.0)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.37.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.22.4-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.20)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.2)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.21.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Installing collected packages: numpy, markdown, grpcio, google-auth-oauthlib, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, astunparse, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\numpy-1.20.3.dist-info\\\\direct_url.json'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe tensorflow scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1f2aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "F\n",
      "H\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "H\n",
      "H\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "D\n",
      "H\n",
      "S\n",
      "A\n",
      "D\n",
      "F\n",
      "H\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "C\n",
      "D\n",
      "F\n",
      "H\n",
      "H\n",
      "A\n",
      "C\n",
      "D\n",
      "H\n",
      "H\n",
      "N\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "C\n",
      "D\n",
      "N\n",
      "S\n",
      "S\n",
      "D\n",
      "F\n",
      "N\n",
      "S\n",
      "C\n",
      "F\n",
      "H\n",
      "H\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "D\n",
      "N\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "C\n",
      "H\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "C\n",
      "D\n",
      "H\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "C\n",
      "C\n",
      "F\n",
      "H\n",
      "N\n",
      "A\n",
      "D\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "F\n",
      "F\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "D\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "C\n",
      "F\n",
      "H\n",
      "N\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "C\n",
      "D\n",
      "D\n",
      "H\n",
      "H\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "C\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "C\n",
      "D\n",
      "D\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "D\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "H\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "D\n",
      "N\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "C\n",
      "F\n",
      "S\n",
      "A\n",
      "D\n",
      "H\n",
      "N\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "C\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "C\n",
      "F\n",
      "H\n",
      "H\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "D\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "C\n",
      "H\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "D\n",
      "H\n",
      "H\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "D\n",
      "D\n",
      "N\n",
      "S\n",
      "A\n",
      "C\n",
      "H\n",
      "N\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n",
      "A\n",
      "A\n",
      "C\n",
      "C\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "H\n",
      "H\n",
      "H\n",
      "N\n",
      "N\n",
      "S\n",
      "S\n",
      "S\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "def extract_word(string):\n",
    "    start_index = string.find('_') + 1  # Find the index of the underscore and add 1 to exclude it\n",
    "    end_index = string.find('.')  # Find the index of the dot\n",
    "\n",
    "    if start_index < end_index and start_index > 0:\n",
    "        return string[start_index:end_index]\n",
    "    else:\n",
    "        return None\n",
    "def extract_name(string):\n",
    "#     start_index = string.find('_') - 3  # Find the index of the underscore and add 1 to exclude it\n",
    "    end_index = string.find('_')  # Find the index of the dot\n",
    "\n",
    "    if 0 < end_index :\n",
    "        return string[0:end_index]\n",
    "    else:\n",
    "        return None\n",
    "def load_dataset(folder_path):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    people = []\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\") or file.endswith(\".png\"):  # Add more extensions if needed\n",
    "                image_path = os.path.join(root, file)\n",
    "                label = os.path.basename(file)\n",
    "                name = extract_name(label)\n",
    "                label = extract_word(label)\n",
    "                \n",
    "                try:\n",
    "                    image = Image.open(image_path)  # Use PIL to open the image\n",
    "                    dataset.append(image)\n",
    "                    labels.append(label[0])\n",
    "                    people.append(name)\n",
    "                except (IOError, OSError):\n",
    "                    print(f\"Error loading image: {image_path}\")\n",
    "\n",
    "    return dataset, labels, people\n",
    "\n",
    "# Example usage\n",
    "data_path = 'RADIATE_JPEGS1'\n",
    "dataset_folder = data_path\n",
    "images, groundlabels, people = load_dataset(dataset_folder)\n",
    "\n",
    "# Access individual images and labels\n",
    "for image, label, person in zip(images, groundlabels,people):\n",
    "    # image.show()  # Display the image using PIL\n",
    "    print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bab73f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize MediaPipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Load pre-trained EfficientNet-B3 model\n",
    "model = EfficientNetB3(weights='imagenet')\n",
    "\n",
    "# Define emotion labels\n",
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "# Load label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load('emotion_classes.npy', allow_pickle=True)\n",
    "\n",
    "# Function to extract face landmarks using MediaPipe FaceMesh\n",
    "def extract_face_landmarks(image):\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1) as face_mesh:\n",
    "        results = face_mesh.process(image)\n",
    "        if results.multi_face_landmarks:\n",
    "            face_landmarks = []\n",
    "            for face_landmark in results.multi_face_landmarks:\n",
    "                for i, landmark in enumerate(face_landmark.landmark):\n",
    "                    face_landmarks.append([landmark.x, landmark.y, landmark.z])\n",
    "            return np.array(face_landmarks)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Function to preprocess face landmarks\n",
    "def preprocess_face_landmarks(face_landmarks):\n",
    "    face_landmarks = face_landmarks.flatten()\n",
    "    face_landmarks = np.expand_dims(face_landmarks, axis=0)\n",
    "    return face_landmarks\n",
    "\n",
    "# Function to predict emotions\n",
    "def predict_emotions(face_landmarks):\n",
    "    # Preprocess face landmarks\n",
    "    face_landmarks = preprocess_face_landmarks(face_landmarks)\n",
    "\n",
    "    # Preprocess input image for EfficientNet-B3\n",
    "    face_image = cv2.resize(face_landmarks, (300, 300))\n",
    "    face_image = preprocess_input(face_image)\n",
    "\n",
    "    # Predict emotions using EfficientNet-B3 model\n",
    "    predictions = model.predict(face_image)\n",
    "    probabilities = np.squeeze(predictions)\n",
    "    emotion_probabilities = dict(zip(emotion_labels, probabilities))\n",
    "    return emotion_probabilities\n",
    "\n",
    "for id,i in enumerate(images):\n",
    "    \n",
    "    # Convert BGR image to RGB\n",
    "    rgb_frame = cv2.cvtColor(np.array(i), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Extract face landmarks\n",
    "    face_landmarks = extract_face_landmarks(rgb_frame)\n",
    "    if face_landmarks is not None:\n",
    "        # Predict emotions\n",
    "        emotion_probabilities = predict_emotions(face_landmarks)\n",
    "\n",
    "        # Get the predicted emotion label\n",
    "        emotion_label = max(emotion_probabilities, key=emotion_probabilities.get)\n",
    "        emotion_prob = emotion_probabilities[emotion_label]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2da781b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\r\n",
      "Version: 2.11.0\r\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author: Google Inc.\r\n",
      "Author-email: packages@tensorflow.org\r\n",
      "License: Apache 2.0\r\n",
      "Location: /usr/local/lib/python3.8/site-packages\r\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\r\n",
      "Required-by: \r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e21d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
